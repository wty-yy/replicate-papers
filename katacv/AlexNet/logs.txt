2023.6.29. 
try1: Adam步长取为1e-3，计算13个epoch的loss仍然是6.9080没有任何变换
try2: 加入两个正则化项层，将Adam步长取为1e-3，梯度有所下降，两个epoch下降0.0005
try3: 将batch size设置为64，再将Adam步长设置为1e-4总算开始训练起来了
根据参数batch_size=64，learning_rate=1e-4训练了25个epoch，训练集正确率达到top1=68%,top5=90%，但验证集正确率只有34%，差距有点大
2023.7.1. 调整参数batch_size=96，步长1e-5，再训练20个epoch，loss=0.6，
训练集准确率达到top1=83%,top5=97%，但验证集只有top1=39%,top5=70%
2023.7.1. 使用参数batch_size=96，步长1e-5，再训练17个epoch，最终loss=0.4620，训练集准确率top1=86.13%,top5=98.34%，验证集准确率top1=38.71%,top5=64%. 说明发生了严重的过拟合，已经没有继续的意义了.